function mergeDIVs(divFolders, outputFolder, varargin)
%% MERGEDIVS Merge spike data from multiple DIV output folders
%
% This function merges spike detection results from multiple DIV output folders
% generated by MEA-NAP pipeline. It focuses specifically on combining data after 
% Step 1 (spike detection) to enable further analysis of developmental trajectories.
%
% USAGE:
%   mergeDIVs(divFolders, outputFolder)
%   mergeDIVs(divFolders, outputFolder, options)
%
% INPUTS:
%   divFolders      - Cell array of strings with paths to DIV folders
%   outputFolder    - String, path to save the merged output
%   options         - (Optional) Struct with the following possible fields:
%       .overwrite          - Logical, whether to overwrite existing output (default: false)
%       .verbose            - Logical, whether to display detailed information (default: true)
%       .mergeExperiments   - Logical, whether to merge experiment mat files (default: true)
%       .copySpikes         - Logical, whether to copy spike files (default: true)
%       .mergeDivCSVs       - Logical, whether to merge DIV CSV files (default: true)
%
% OUTPUTS:
%   Creates a merged output folder containing:
%   - Combined spike detection data
%   - Merged DIV CSV file
%   - Unified parameter files
%   - Experiment mat files
%
% This function assumes that all input folders contain spike detection results
% from MEA-NAP and that the recordings were made on the same type of MEA grid.
%
% EXAMPLES:
%   % Merge two DIV folders
%   divFolders = {'/path/to/DIV5/div5', '/path/to/DIV10/div10'};
%   outputFolder = '/path/to/output/MergedDIVs';
%   mergeDIVs(divFolders, outputFolder);
%
%   % Merge with custom options
%   options.overwrite = true;
%   options.verbose = true;
%   mergeDIVs(divFolders, outputFolder, options);
%
% Author: Avinash

%% Parse input arguments
if nargin < 2
    error('Not enough input arguments. At least divFolders and outputFolder must be specified.');
end

% Set default options
options = struct(...
    'overwrite', false, ...
    'verbose', true, ...
    'mergeExperiments', true, ...
    'copySpikes', true, ...
    'mergeDivCSVs', true);

% Override defaults with user specified options
if nargin > 2
    userOptions = varargin{1};
    if ~isstruct(userOptions)
        error('Options must be provided as a struct.');
    end
    
    fields = fieldnames(userOptions);
    for i = 1:length(fields)
        if isfield(options, fields{i})
            options.(fields{i}) = userOptions.(fields{i});
        else
            warning('Unknown option: %s', fields{i});
        end
    end
end

% Ensure divFolders is a cell array
if ~iscell(divFolders)
    divFolders = {divFolders};
end

%% Initial validation
% Display function header
if options.verbose
    fprintf('=================================================\n');
    fprintf('MEA-NAP DIV Spike Data Merger\n');
    fprintf('=================================================\n\n');
    fprintf('Starting merge of %d DIV folders...\n', length(divFolders));
end

% Check if output folder exists
if exist(outputFolder, 'dir')
    if ~options.overwrite
        error('Output folder already exists. Use options.overwrite=true to overwrite.');
    elseif options.verbose
        fprintf('Output folder exists and will be overwritten.\n');
    end
else
    % Create output folder
    if options.verbose
        fprintf('Creating output folder: %s\n', outputFolder);
    end
    mkdir(outputFolder);
end

% Validate input folders
validFolders = {};
divNumbers = zeros(1, length(divFolders));

for i = 1:length(divFolders)
    % Check if folder exists
    if ~exist(divFolders{i}, 'dir')
        warning('Folder does not exist: %s - skipping', divFolders{i});
        continue;
    end
    
    % Check for spike detection folder
    spikeFolder = fullfile(divFolders{i}, '1_SpikeDetection');
    spikeDataFolder = fullfile(spikeFolder, '1A_SpikeDetectedData');
    if ~exist(spikeDataFolder, 'dir')
        warning('No spike data folder found in: %s - skipping', divFolders{i});
        continue;
    end
    
    % Check for parameter file
    paramFiles = dir(fullfile(divFolders{i}, 'Parameters_*.mat'));
    if isempty(paramFiles)
        warning('No parameter file found in: %s - skipping', divFolders{i});
        continue;
    end
    
    % Try to extract DIV number from folder name or DIV CSV file
    divCSV = dir(fullfile(divFolders{i}, 'div*.csv'));
    if ~isempty(divCSV)
        % Extract DIV number from CSV filename
        divMatch = regexp(divCSV(1).name, 'div(\d+)', 'tokens');
        if ~isempty(divMatch) && ~isempty(divMatch{1})
            divNumbers(i) = str2double(divMatch{1}{1});
        else
            % Try to extract from folder name
            [~, folderName] = fileparts(divFolders{i});
            divMatch = regexp(folderName, '(DIV|div)(\d+)', 'tokens');
            if ~isempty(divMatch) && ~isempty(divMatch{1})
                if length(divMatch{1}) > 1
                    divNumbers(i) = str2double(divMatch{1}{2}); % Get the number part
                else
                    divNumbers(i) = str2double(regexprep(divMatch{1}{1}, 'DIV|div', ''));
                end
            else
                divNumbers(i) = i; % Default sequential numbering
            end
        end
    else
        % Try folder name if no CSV
        [~, folderName] = fileparts(divFolders{i});
        divMatch = regexp(folderName, '(DIV|div)(\d+)', 'tokens');
        if ~isempty(divMatch) && ~isempty(divMatch{1})
            if length(divMatch{1}) > 1
                divNumbers(i) = str2double(divMatch{1}{2}); % Get the number part
            else
                divNumbers(i) = str2double(regexprep(divMatch{1}{1}, 'DIV|div', ''));
            end
        else
            divNumbers(i) = i; % Default sequential numbering
        end
    end
    
    validFolders{end+1} = divFolders{i};
    if options.verbose
        fprintf('✓ Validated folder: %s (DIV %d)\n', divFolders{i}, divNumbers(i));
    end
end

% Check if we have any valid folders
if isempty(validFolders)
    error('No valid DIV folders found. Please check your input folders.');
end

% Sort folders by DIV number
[divNumbers, sortIdx] = sort(divNumbers(1:length(validFolders)));
validFolders = validFolders(sortIdx);

if options.verbose
    fprintf('\nProcessing folders in DIV order:\n');
    for i = 1:length(validFolders)
        fprintf('  DIV %d: %s\n', divNumbers(i), validFolders{i});
    end
    fprintf('\n');
end

%% Create output folder structure
% Create spike detection folders
spikeOutputFolder = fullfile(outputFolder, '1_SpikeDetection');
spikeDataOutputFolder = fullfile(spikeOutputFolder, '1A_SpikeDetectedData');
spikeChecksOutputFolder = fullfile(spikeOutputFolder, '1B_SpikeDetectionChecks');

if ~exist(spikeOutputFolder, 'dir')
    mkdir(spikeOutputFolder);
end
if ~exist(spikeDataOutputFolder, 'dir')
    mkdir(spikeDataOutputFolder);
end
if ~exist(spikeChecksOutputFolder, 'dir')
    mkdir(spikeChecksOutputFolder);
end

% Create ExperimentMatFiles folder
experimentMatFolder = fullfile(outputFolder, 'ExperimentMatFiles');
if ~exist(experimentMatFolder, 'dir')
    mkdir(experimentMatFolder);
end

%% Copy spike data files
if options.copySpikes
    if options.verbose
        fprintf('Copying spike data files...\n');
    end
    
    spikeFileCounter = 0;
    
    for i = 1:length(validFolders)
        sourceFolder = fullfile(validFolders{i}, '1_SpikeDetection', '1A_SpikeDetectedData');
        spikeFiles = dir(fullfile(sourceFolder, '*_spikes.mat'));
        
        for j = 1:length(spikeFiles)
            copyfile(fullfile(sourceFolder, spikeFiles(j).name), ...
                    fullfile(spikeDataOutputFolder, spikeFiles(j).name));
            spikeFileCounter = spikeFileCounter + 1;
        end
        
        % Also copy spike detection check folders if they exist
        sourceChecksFolder = fullfile(validFolders{i}, '1_SpikeDetection', '1B_SpikeDetectionChecks');
        if exist(sourceChecksFolder, 'dir')
            % Get all subdirectories (group folders)
            groupFolders = dir(sourceChecksFolder);
            groupFolders = groupFolders([groupFolders.isdir]);
            groupFolders = groupFolders(~ismember({groupFolders.name}, {'.', '..'}));
            
            for j = 1:length(groupFolders)
                groupName = groupFolders(j).name;
                targetGroupFolder = fullfile(spikeChecksOutputFolder, groupName);
                
                if ~exist(targetGroupFolder, 'dir')
                    mkdir(targetGroupFolder);
                end
                
                % Copy recording folders for this group
                recordingFolders = dir(fullfile(sourceChecksFolder, groupName));
                recordingFolders = recordingFolders([recordingFolders.isdir]);
                recordingFolders = recordingFolders(~ismember({recordingFolders.name}, {'.', '..'}));
                
                for k = 1:length(recordingFolders)
                    recordingName = recordingFolders(k).name;
                    sourceRecFolder = fullfile(sourceChecksFolder, groupName, recordingName);
                    targetRecFolder = fullfile(spikeChecksOutputFolder, groupName, recordingName);
                    
                    if ~exist(targetRecFolder, 'dir')
                        mkdir(targetRecFolder);
                        
                        % Copy all check images
                        checkImages = dir(fullfile(sourceRecFolder, '*.png'));
                        for img = 1:length(checkImages)
                            copyfile(fullfile(sourceRecFolder, checkImages(img).name), targetRecFolder);
                        end
                    end
                end
            end
        end
    end
    
    if options.verbose
        fprintf('✓ Copied %d spike data files\n', spikeFileCounter);
    end
end

%% Merge DIV CSV files
if options.mergeDivCSVs
    if options.verbose
        fprintf('\nMerging DIV CSV files...\n');
    end
    
    % Collect all CSV data
    allCSVData = {};
    for i = 1:length(validFolders)
        divCSV = dir(fullfile(validFolders{i}, 'div*.csv'));
        if ~isempty(divCSV)
            try
                data = readtable(fullfile(validFolders{i}, divCSV(1).name));
                
                % Add DIV column if not present
                if ~any(strcmpi(data.Properties.VariableNames, 'DIV'))
                    if divNumbers(i) > 0
                        data.DIV = repmat(divNumbers(i), height(data), 1);
                    end
                end
                
                allCSVData{end+1} = data;
            catch ME
                warning('Error reading CSV file %s: %s', divCSV(1).name, ME.message);
            end
        end
    end
    
    % Combine all tables
    if ~isempty(allCSVData)
        % Find common column names across all tables
        allVarNames = cellfun(@(x) x.Properties.VariableNames, allCSVData, 'UniformOutput', false);
        commonVarNames = allVarNames{1};
        
        for i = 2:length(allVarNames)
            commonVarNames = intersect(commonVarNames, allVarNames{i});
        end
        
        % Select only common columns
        for i = 1:length(allCSVData)
            allCSVData{i} = allCSVData{i}(:, commonVarNames);
        end
        
        % Combine tables
        combinedCSV = vertcat(allCSVData{:});
        
        % Sort by DIV if present
        if any(strcmpi(combinedCSV.Properties.VariableNames, 'DIV'))
            combinedCSV = sortrows(combinedCSV, 'DIV');
        end
        
        % Generate output filename
        csvOutputFile = fullfile(outputFolder, 'div_merged.csv');
        
        % Check if we need to match the original folder's CSV header format
        % First check if we can find the format from any source folder
        originalHeaderFormat = 'standard'; % Default format
        for i = 1:length(validFolders)
            divCSV = dir(fullfile(validFolders{i}, 'div*.csv'));
            if ~isempty(divCSV)
                try
                    % Read first line to get header
                    fid = fopen(fullfile(validFolders{i}, divCSV(1).name), 'r');
                    if fid ~= -1
                        headerLine = fgetl(fid);
                        fclose(fid);
                        
                        % Check header format
                        if contains(headerLine, 'Recording filename')
                            originalHeaderFormat = 'recording_format';
                            break;
                        end
                    end
                catch
                    % If error, continue with next folder
                    if fid ~= -1
                        fclose(fid);
                    end
                end
            end
        end
        
        % Handle different formats based on detected format
        if strcmp(originalHeaderFormat, 'recording_format')
            % This matches the merger3855_nap format with "Recording filename,DIV group,Genotype,Ground"
            % The columns are already in the right order, just need to rename
            combinedCSV.Properties.VariableNames{1} = 'Recording filename';
            combinedCSV.Properties.VariableNames{2} = 'DIV';
            combinedCSV.Properties.VariableNames{3} = 'group';
            if any(strcmpi(combinedCSV.Properties.VariableNames, 'ground'))
                combinedCSV.Properties.VariableNames{strcmpi(combinedCSV.Properties.VariableNames, 'ground')} = 'Ground';
            else
                combinedCSV.Ground = repmat({''},height(combinedCSV),1);
            end
            
            % Set Genotype column if it exists
            if any(strcmpi(combinedCSV.Properties.VariableNames, 'Genotype'))
                % Already has Genotype column
            elseif any(strcmpi(combinedCSV.Properties.VariableNames, 'group'))
                % Use group as Genotype
                columnIdx = find(strcmpi(combinedCSV.Properties.VariableNames, 'group'));
                combinedCSV.Properties.VariableNames{columnIdx} = 'Genotype';
            end
            
            % Reorder columns to match expected format
            expectedCols = {'Recording filename', 'DIV', 'Genotype', 'Ground'};
            availableCols = intersect(expectedCols, combinedCSV.Properties.VariableNames, 'stable');
            otherCols = setdiff(combinedCSV.Properties.VariableNames, expectedCols, 'stable');
            combinedCSV = combinedCSV(:, [availableCols, otherCols]);
        else
            % Standard format with filename, DIV, group, ground
            if ~any(strcmpi(combinedCSV.Properties.VariableNames, 'ground'))
                combinedCSV.ground = repmat({''},height(combinedCSV),1);
            end
            
            % Reorder columns
            orderedCols = {'filename', 'DIV', 'group', 'ground'};
            availableCols = intersect(orderedCols, combinedCSV.Properties.VariableNames, 'stable');
            otherCols = setdiff(combinedCSV.Properties.VariableNames, orderedCols, 'stable');
            combinedCSV = combinedCSV(:, [availableCols, otherCols]);
            
            % Rename columns if needed to match expected names
            targetNames = {'filename', 'DIV', 'group', 'ground'};
            currentNames = combinedCSV.Properties.VariableNames(1:min(4,width(combinedCSV)));
            for i = 1:length(currentNames)
                if ~strcmpi(currentNames{i}, targetNames{i})
                    combinedCSV.Properties.VariableNames{i} = targetNames{i};
                end
            end
            
            % Add RecordingFilename column if it doesn't exist
            if ~any(strcmpi(combinedCSV.Properties.VariableNames, 'RecordingFilename'))
                % Try to extract recording name from filename
                if any(strcmpi(combinedCSV.Properties.VariableNames, 'filename'))
                    combinedCSV.RecordingFilename = combinedCSV.filename;
                end
            end
        end
        
        % Write to CSV
        writetable(combinedCSV, csvOutputFile);
        
        if options.verbose
            fprintf('✓ Created merged CSV file: %s\n', csvOutputFile);
            fprintf('  Contains %d recordings across %d DIV timepoints\n', ...
                height(combinedCSV), length(unique(combinedCSV.DIV)));
        end
    else
        warning('No DIV CSV files found to merge.');
    end
end

%% Generate parameter files in the format matching MEA-NAP
if options.verbose
    fprintf('\nGenerating parameter files in MEA-NAP format...\n');
end

% Get output folder name for file naming
[~, outputFolderName] = fileparts(outputFolder);
if isempty(outputFolderName)
    outputFolderName = 'MergedDIVs';
end

%% Merge Parameter Files

% Load all parameter files
allParams = cell(1, length(validFolders));
for i = 1:length(validFolders)
    paramFiles = dir(fullfile(validFolders{i}, 'Parameters_*.mat'));
    if ~isempty(paramFiles)
        paramData = load(fullfile(validFolders{i}, paramFiles(1).name));
        if isfield(paramData, 'Params')
            allParams{i} = paramData.Params;
        else
            warning('Parameters not found in %s - skipping', paramFiles(1).name);
        end
    end
end

% Start with the first one as the base
if ~isempty(allParams) && ~isempty(allParams{1})
    % Initialize the structured parameters object
    StructuredParams = struct();
    
    % Base Params (regular flat structure for compatibility with existing code)
    Params = allParams{1};
    
    %% 1. Version information
    StructuredParams.version = struct();
    StructuredParams.version.version = '1.10.2'; % Use standard version
    StructuredParams.version.buildDate = datestr(now, 'ddmmmyyyy');
    
    %% 2. File Management parameters
    StructuredParams.fileManagement = struct();
    StructuredParams.fileManagement.paths = struct();
    StructuredParams.fileManagement.files = struct();
    StructuredParams.fileManagement.priorAnalysis = struct();
    StructuredParams.fileManagement.pipelineControl = struct();
    StructuredParams.fileManagement.outputFormat = struct();
    
    % Path settings
    StructuredParams.fileManagement.paths.homeDir = '/Users/avinash/Documents/labwork/MEA-NAP';
    StructuredParams.fileManagement.paths.outputDataFolder = outputFolder;
    StructuredParams.fileManagement.paths.outputDataFolderName = outputFolderName;
    StructuredParams.fileManagement.paths.rawData = '';
    StructuredParams.fileManagement.paths.spikeDetectedData = '';
    
    % File settings
    divCsvPath = fullfile(outputFolder, 'div_merged.csv');
    if exist(divCsvPath, 'file')
        StructuredParams.fileManagement.files.spreadSheetFileName = divCsvPath;
        StructuredParams.fileManagement.files.spreadSheetRange = 'A1:Z100'; % Default range
    end
    
    % Prior analysis settings
    if isfield(Params, 'priorAnalysis')
        StructuredParams.fileManagement.priorAnalysis.priorAnalysis = Params.priorAnalysis;
    else
        StructuredParams.fileManagement.priorAnalysis.priorAnalysis = false;
    end
    StructuredParams.fileManagement.priorAnalysis.priorAnalysisFolderName = '';
    
    % Pipeline control
    StructuredParams.fileManagement.pipelineControl.startAnalysisStep = 1;
    StructuredParams.fileManagement.pipelineControl.optionalStepsToRun = [];
    StructuredParams.fileManagement.pipelineControl.recomputeMetrics = false;
    StructuredParams.fileManagement.pipelineControl.metricsToRecompute = {};
    
    % Output format
    if isfield(Params, 'figExt')
        StructuredParams.fileManagement.outputFormat.figExt = Params.figExt;
    else
        StructuredParams.fileManagement.outputFormat.figExt = 'png';
    end
    StructuredParams.fileManagement.outputFormat.fullSVG = false;
    
    %% 3. Recording Parameters
    StructuredParams.recordingParameters = struct();
    StructuredParams.recordingParameters.acquisitionSettings = struct();
    StructuredParams.recordingParameters.recordingLimits = struct();
    StructuredParams.recordingParameters.divInfo = struct();
    
    % Acquisition settings
    if isfield(Params, 'fs')
        StructuredParams.recordingParameters.acquisitionSettings.fs = Params.fs;
    else
        StructuredParams.recordingParameters.acquisitionSettings.fs = 25000; % Default sample rate
    end
    
    if isfield(Params, 'dSampF')
        StructuredParams.recordingParameters.acquisitionSettings.dSampF = Params.dSampF;
    else
        StructuredParams.recordingParameters.acquisitionSettings.dSampF = 1000; % Default downsample factor
    end
    
    StructuredParams.recordingParameters.acquisitionSettings.potentialDifferenceUnit = 'uV';
    StructuredParams.recordingParameters.acquisitionSettings.channelLayout = 'Axion16';
    
    % Recording limits
    StructuredParams.recordingParameters.recordingLimits.TruncRec = false;
    StructuredParams.recordingParameters.recordingLimits.TruncLength = 300;
    
    % DIV information
    if isnumeric(divNumbers)
        StructuredParams.recordingParameters.divInfo.DivNm = strjoin(cellstr(string(divNumbers)), ',');
    else
        StructuredParams.recordingParameters.divInfo.DivNm = divNumbers;
    end
    
    %% 4. Spike Detection parameters
    StructuredParams.spikeDetection = struct();
    StructuredParams.spikeDetection.generalSettings = struct();
    StructuredParams.spikeDetection.thresholdSettings = struct();
    StructuredParams.spikeDetection.waveletSettings = struct();
    StructuredParams.spikeDetection.templateSettings = struct();
    StructuredParams.spikeDetection.filterSettings = struct();
    StructuredParams.spikeDetection.chunkProcessing = struct();
    
    % General spike detection settings
    StructuredParams.spikeDetection.generalSettings.detectSpikes = true;
    StructuredParams.spikeDetection.generalSettings.runSpikeCheckOnPrevSpikeData = false;
    StructuredParams.spikeDetection.generalSettings.showOneFig = true;
    
    if isfield(Params, 'SpikesMethod')
        StructuredParams.spikeDetection.generalSettings.SpikesMethod = Params.SpikesMethod;
    else
        StructuredParams.spikeDetection.generalSettings.SpikesMethod = 'Bakkum';
    end
    
    StructuredParams.spikeDetection.generalSettings.minActivityLevel = 0.01;
    StructuredParams.spikeDetection.generalSettings.removeInactiveNodes = true;
    
    % Threshold settings
    if isfield(Params, 'thresholds')
        StructuredParams.spikeDetection.thresholdSettings.thresholds = Params.thresholds;
    else
        StructuredParams.spikeDetection.thresholdSettings.thresholds = [10, 3];
    end
    
    StructuredParams.spikeDetection.thresholdSettings.multiplier = 1.3;
    StructuredParams.spikeDetection.thresholdSettings.custom_threshold_method_name = 'automatic';
    StructuredParams.spikeDetection.thresholdSettings.remove_artifacts = true;
    StructuredParams.spikeDetection.thresholdSettings.minPeakThrMultiplier = 1;
    StructuredParams.spikeDetection.thresholdSettings.maxPeakThrMultiplier = 2.05;
    StructuredParams.spikeDetection.thresholdSettings.posPeakThrMultiplier = 0;
    
    % Wavelet settings
    if isfield(Params, 'wnameList')
        if iscell(Params.wnameList) && length(Params.wnameList) >= 3
            StructuredParams.spikeDetection.waveletSettings.wnameList_1 = Params.wnameList{1};
            StructuredParams.spikeDetection.waveletSettings.wnameList_2 = Params.wnameList{2};
            StructuredParams.spikeDetection.waveletSettings.wnameList_3 = Params.wnameList{3};
        end
    else
        StructuredParams.spikeDetection.waveletSettings.wnameList_1 = 'Bakkum';
        StructuredParams.spikeDetection.waveletSettings.wnameList_2 = '10';
        StructuredParams.spikeDetection.waveletSettings.wnameList_3 = 'Covariance';
    end
    
    StructuredParams.spikeDetection.waveletSettings.nScales = 10;
    StructuredParams.spikeDetection.waveletSettings.wid_1 = 10;
    StructuredParams.spikeDetection.waveletSettings.wid_2 = 0;
    StructuredParams.spikeDetection.waveletSettings.grd = 0.25;
    
    % Template settings
    StructuredParams.spikeDetection.templateSettings.refPeriod = 0.525;
    StructuredParams.spikeDetection.templateSettings.getTemplateRefPeriod = 0.45;
    StructuredParams.spikeDetection.templateSettings.nSpikes = 0.8;
    StructuredParams.spikeDetection.templateSettings.multiple_templates = 0.75;
    StructuredParams.spikeDetection.templateSettings.multi_template_method = '0.996';
    
    % Filter settings
    StructuredParams.spikeDetection.filterSettings.filterLowPass = 0.78;
    StructuredParams.spikeDetection.filterSettings.filterHighPass = 0.459;
    
    % Chunk processing
    StructuredParams.spikeDetection.chunkProcessing.run_detection_in_chunks = true;
    StructuredParams.spikeDetection.chunkProcessing.chunk_length = 20;
    
    %% 5. Network Analysis parameters
    StructuredParams.networkAnalysis = struct();
    StructuredParams.networkAnalysis.connectivity = struct();
    StructuredParams.networkAnalysis.thresholding = struct();
    StructuredParams.networkAnalysis.communityDetection = struct();
    StructuredParams.networkAnalysis.nodeCartography = struct();
    StructuredParams.networkAnalysis.networkMetrics = struct();
    StructuredParams.networkAnalysis.boundaries = struct();
    
    % Connectivity settings
    if isfield(Params, 'adjMtype')
        StructuredParams.networkAnalysis.connectivity.adjMtype = Params.adjMtype;
    else
        StructuredParams.networkAnalysis.connectivity.adjMtype = 'STTC';
    end
    
    if isfield(Params, 'FuncConLagval')
        StructuredParams.networkAnalysis.connectivity.FuncConLagval = Params.FuncConLagval;
    else
        StructuredParams.networkAnalysis.connectivity.FuncConLagval = 0.01;
    end
    
    % Thresholding settings
    StructuredParams.networkAnalysis.thresholding.ProbThreshRepNum = 1000;
    StructuredParams.networkAnalysis.thresholding.ProbThreshTail = 'Linear';
    StructuredParams.networkAnalysis.thresholding.ProbThreshPlotChecks = true;
    StructuredParams.networkAnalysis.thresholding.ProbThreshPlotChecksN = 0.3;
    StructuredParams.networkAnalysis.thresholding.excludeEdgesBelowThreshold = true;
    StructuredParams.networkAnalysis.thresholding.minNumberOfNodesToCalNetMet = 5;
    
    % Community detection settings
    if isfield(Params, 'effRank')
        StructuredParams.networkAnalysis.communityDetection.effRank = Params.effRank;
    else
        StructuredParams.networkAnalysis.communityDetection.effRank = 0;
    end
    
    StructuredParams.networkAnalysis.communityDetection.num_nnmf_components = 99;
    StructuredParams.networkAnalysis.communityDetection.nComponentsRelNS = 'Bakkum';
    StructuredParams.networkAnalysis.communityDetection.SVCA_alpha = 10;
    
    % Node cartography settings
    StructuredParams.networkAnalysis.nodeCartography.autoSetCartographyBoudariesPerLag = true;
    StructuredParams.networkAnalysis.nodeCartography.cartographyLagVal = 0.01;
    StructuredParams.networkAnalysis.nodeCartography.autoSetCartographyBoundaries = true;
    
    % Network metrics settings
    % Add comprehensive list of network metrics including BCmeantop5
    if isfield(Params, 'netMetToCal')
        if ~any(strcmp(Params.netMetToCal, 'BCmeantop5'))
            Params.netMetToCal{end+1} = 'BCmeantop5';
        end
        StructuredParams.networkAnalysis.networkMetrics.netMetToCal = Params.netMetToCal;
        
        % Also store each individual metric in the structured format
        for i = 1:length(Params.netMetToCal)
            metricField = ['netMetToCal_' num2str(i)];
            StructuredParams.networkAnalysis.networkMetrics.(metricField) = Params.netMetToCal{i};
        end
    else
        % Create standard list of metrics to calculate
        standardMetrics = {
            'aN', 'Dens', 'ND', 'MEW', 'NS', 'BC', 'BCmeantop5', 'NDmean', 'NDtop25', 
            'sigEdgesMean', 'sigEdgesTop10', 'NSmean', 'Eloc', 'ElocMean', 'CC', 
            'Z', 'PC', 'PCmean', 'PCmeanBottom10', 'PCmeanTop10', 'Eglob',
            'nMod', 'Q', 'PL', 'SW', 'SWw', 'effRank', 'num_nnmf_components', 'nComponentsRelNS'
        };
        StructuredParams.networkAnalysis.networkMetrics.netMetToCal = standardMetrics;
        
        % Store each individual metric
        for i = 1:length(standardMetrics)
            metricField = ['netMetToCal_' num2str(i)];
            StructuredParams.networkAnalysis.networkMetrics.(metricField) = standardMetrics{i};
        end
    end
    
    % Add NetMetLabelDict
    if isfield(Params, 'NetMetLabelDict')
        if ~any(strcmp({Params.NetMetLabelDict{:, 1}}, 'BCmeantop5'))
            bcRow = size(Params.NetMetLabelDict, 1) + 1;
            Params.NetMetLabelDict(bcRow, :) = {'BCmeantop5', 'Top 5% betweenness centrality mean', 'network'};
        end
        StructuredParams.networkAnalysis.networkMetrics.NetMetLabelDict = Params.NetMetLabelDict;
    else
        % Define standard metrics dictionary
        StructuredParams.networkAnalysis.networkMetrics.NetMetLabelDict = {
            'aN',  'network size', 'network'; ...  
            'Dens', 'density', 'network'; ...
            'NDmean', 'Node degree mean', 'network'; ...
            'NDtop25', 'Top 25% node degree', 'network'; ...
            'sigEdgesMean', 'Significant edge weight mean', 'network'; ...  
            'sigEdgesTop10', 'Top 10% edge weight mean', 'network'; ... 
            'NSmean', 'Node strength mean', 'network'; ... 
            'ElocMean', 'Local efficiency mean', 'network'; ... 
            'CC', 'clustering coefficient', 'network'; ...
            'nMod', 'number of modules', 'network'; ...
            'Q', 'modularity score', 'network'; ...
            'percentZscoreGreaterThanZero',  'Percentage within-module z-score > 0', 'network'; ...
            'percentZscoreLessThanZero', 'Percentage within-module z-score < 0', 'network'; ...
            'PL', 'mean path length', 'network'; ...
            'PCmean', 'Participant coefficient (PC) mean', 'network'; ... 
            'PCmeanBottom10', 'Bottom 10% PC', 'network'; ...
            'PCmeanTop10', 'Top 10% PC', 'network'; ... 
            'Eglob', 'global efficiency', 'network'; ...
            'NCpn1', 'NC1PeripheralNodes', 'network'; ... 
            'NCpn2', 'NC2NonhubConnectors', 'network'; ... 
            'NCpn3', 'NC3NonhubKinless', 'network'; ... 
            'NCpn4', 'NC4ProvincialHubs', 'network'; ...
            'NCpn5', 'NC5ConnectorHubs', 'network'; ... 
            'NCpn6', 'NC6KinlessHubs', 'network'; ... 
            'SW', 'small worldness \sigma', 'network'; ...
            'SWw', 'small worldness \omega', 'network'; ...
            'aveControlMean', 'Mean average controllability', 'network'; ... 
            'modalControlMean', 'Mean modal controllability', 'network'; ...
            'num_nnmf_components', 'Num NMF components', 'network'; ...
            'nComponentsRelNS', 'nNMF div network size', 'network'; ... 
            'effRank', 'Effective rank', 'network'; ...
            'ND', 'node degree', 'node'; ...
            'MEW','edge weight', 'node'; ...
            'NS', 'node strength', 'node'; ...
            'Eloc', 'local efficiency', 'node'; ...
            'Z',  'within-module degree z-score', 'node'; ...
            'BC', 'betweenness centrality', 'node'; ...
            'BCmeantop5', 'Top 5% betweenness centrality mean', 'network'; ...
            'PC', 'participation coefficient', 'node'; ...
            'aveControl', 'Average Controllability', 'node'; ...
            'modalControl', 'Modal Controllability', 'node'; ...
        };
    end
    
    % Boundaries settings
    StructuredParams.networkAnalysis.boundaries.use_theoretical_bounds = false;
    StructuredParams.networkAnalysis.boundaries.use_min_max_all_recording_bounds = true;
    StructuredParams.networkAnalysis.boundaries.use_min_max_per_genotype_bounds = false;
    
    % Setup metric bounds
    if isfield(Params, 'networkLevelNetMetCustomBounds')
        StructuredParams.networkAnalysis.boundaries.networkLevelNetMetCustomBounds = Params.networkLevelNetMetCustomBounds;
        
        % Ensure BCmeantop5 bounds exist
        if ~isfield(StructuredParams.networkAnalysis.boundaries.networkLevelNetMetCustomBounds, 'BCmeantop5')
            StructuredParams.networkAnalysis.boundaries.networkLevelNetMetCustomBounds.BCmeantop5 = [0, 1];
        end
    else
        % Create comprehensive bounds
        boundsStruct = struct();
        boundsStruct.effRank = [1, nan];
        boundsStruct.Dens = [0, 1];
        boundsStruct.num_nnmf_components = [1, nan];
        boundsStruct.BC = [0, 1];
        boundsStruct.BCmeantop5 = [0, 1];
        boundsStruct.PC = [0, 0.5];
        boundsStruct.PC_norm = [0, 0.67];
        boundsStruct.CC = [0, 0.114];
        boundsStruct.Eglob = [0, 0.306];
        boundsStruct.Eloc = [0, 0.5];
        boundsStruct.PL = [0, 0.318];
        boundsStruct.SW = [0, 0.114];
        boundsStruct.nMod = [0, 0.376];
        boundsStruct.MS = [0, 0.659];
        boundsStruct.Dens = [0, 0.5];
        
        StructuredParams.networkAnalysis.boundaries.networkLevelNetMetCustomBounds = boundsStruct;
    end
    
    %% 6. Visualization parameters
    StructuredParams.visualization = struct();
    StructuredParams.visualization.generalPlotting = struct();
    StructuredParams.visualization.networkPlots = struct();
    StructuredParams.visualization.nodeCartographyPlotting = struct();
    
    % General plotting settings
    colorMaps = struct();
    colorMaps.parula = true;
    StructuredParams.visualization.generalPlotting.colorMaps = colorMaps;
    
    % Network plotting settings - extract from original params if available
    if isfield(Params, 'networkLevelNetMetToPlot')
        StructuredParams.visualization.networkPlots.networkLevelNetMetToPlot = Params.networkLevelNetMetToPlot;
        
        % Store individual metrics
        for i = 1:length(Params.networkLevelNetMetToPlot)
            metricField = ['networkLevelNetMetToPlot_' num2str(i)];
            StructuredParams.visualization.networkPlots.(metricField) = Params.networkLevelNetMetToPlot{i};
        end
    else
        % Default network metrics to plot
        defaultNetworkMetrics = {
            'Clustering_coef', 'Modularity', 'Path_length',
            'Global_efficiency', 'Small_worldness_norm', 'Density'
        };
        
        StructuredParams.visualization.networkPlots.networkLevelNetMetToPlot = defaultNetworkMetrics;
        
        % Store individual metrics
        for i = 1:length(defaultNetworkMetrics)
            metricField = ['networkLevelNetMetToPlot_' num2str(i)];
            StructuredParams.visualization.networkPlots.(metricField) = defaultNetworkMetrics{i};
        end
    end
    
    % Network metrics labels
    if isfield(Params, 'networkLevelNetMetLabels')
        StructuredParams.visualization.networkPlots.networkLevelNetMetLabels = Params.networkLevelNetMetLabels;
        
        % Store individual labels
        for i = 1:length(Params.networkLevelNetMetLabels)
            labelField = ['networkLevelNetMetLabels_' num2str(i)];
            StructuredParams.visualization.networkPlots.(labelField) = Params.networkLevelNetMetLabels{i};
        end
    else
        % Default network metric labels
        defaultNetworkLabels = {
            'Clustering Coefficient', 'Modularity', 'Path Length',
            'Global Efficiency', 'Small-Worldness', 'Density'
        };
        
        StructuredParams.visualization.networkPlots.networkLevelNetMetLabels = defaultNetworkLabels;
        
        % Store individual labels
        for i = 1:length(defaultNetworkLabels)
            labelField = ['networkLevelNetMetLabels_' num2str(i)];
            StructuredParams.visualization.networkPlots.(labelField) = defaultNetworkLabels{i};
        end
    end
    
    % Unit-level metrics to plot
    if isfield(Params, 'unitLevelNetMetToPlot')
        StructuredParams.visualization.networkPlots.unitLevelNetMetToPlot = Params.unitLevelNetMetToPlot;
        
        % Store individual metrics
        for i = 1:length(Params.unitLevelNetMetToPlot)
            metricField = ['unitLevelNetMetToPlot_' num2str(i)];
            StructuredParams.visualization.networkPlots.(metricField) = Params.unitLevelNetMetToPlot{i};
        end
    else
        % Default unit-level metrics
        defaultUnitMetrics = {
            'Betweenness_centrality', 'Participation_coefficient', 
            'Node_degree', 'Edge_weight'
        };
        
        StructuredParams.visualization.networkPlots.unitLevelNetMetToPlot = defaultUnitMetrics;
        
        % Store individual metrics
        for i = 1:length(defaultUnitMetrics)
            metricField = ['unitLevelNetMetToPlot_' num2str(i)];
            StructuredParams.visualization.networkPlots.(metricField) = defaultUnitMetrics{i};
        end
    end
    
    % Unit-level metric labels
    if isfield(Params, 'unitLevelNetMetLabels')
        StructuredParams.visualization.networkPlots.unitLevelNetMetLabels = Params.unitLevelNetMetLabels;
        
        % Store individual labels
        for i = 1:length(Params.unitLevelNetMetLabels)
            labelField = ['unitLevelNetMetLabels_' num2str(i)];
            StructuredParams.visualization.networkPlots.(labelField) = Params.unitLevelNetMetLabels{i};
        end
    else
        % Default unit-level labels
        defaultUnitLabels = {
            'Betweenness Centrality', 'Participation Coefficient',
            'Node Degree', 'Edge Weight'
        };
        
        StructuredParams.visualization.networkPlots.unitLevelNetMetLabels = defaultUnitLabels;
        
        % Store individual labels
        for i = 1:length(defaultUnitLabels)
            labelField = ['unitLevelNetMetLabels_' num2str(i)];
            StructuredParams.visualization.networkPlots.(labelField) = defaultUnitLabels{i};
        end
    end
    
    % Node cartography plotting
    aesthetics = struct();
    
    % Add comprehensive spike method color scheme (21 colors)
    colors = [
        0         0.4470    0.7410;
        0.8500    0.3250    0.0980;
        0.9290    0.6940    0.1250;
        0.4940    0.1840    0.5560;
        0.4660    0.6740    0.1880;
        0.3010    0.7450    0.9330;
        0.6350    0.0780    0.1840;
        % Additional colors for compatibility with original format
        0.2000    0.8000    0.8000;
        0.9000    0.1000    0.6000;
        0.5000    0.2000    0.9000;
        0.8000    0.8000    0.1000;
        0.2000    0.7000    0.5000;
        0.9000    0.4000    0.3000;
        0.4000    0.5000    0.7000;
        0.7000    0.2000    0.3000;
        0.3000    0.6000    0.1000;
        0.6000    0.3000    0.6000;
        0.8000    0.5000    0.2000;
        0.5000    0.8000    0.6000;
        0.2000    0.4000    0.3000;
        0.1000    0.1000    0.9000
    ];
    
    % Create the color array in flattened form for the aesthetics structure
    aesthetics.spikeMethodColors = reshape(colors', 1, []);
    StructuredParams.visualization.nodeCartographyPlotting.aesthetics = aesthetics;
    
    % Also assign colors to the regular Params structure (needed for flat format)
    Params.spikeMethodColors = colors;
    
    %% 7. Channel Mapping
    StructuredParams.channelMapping = struct();
    StructuredParams.channelMapping.channels = struct();
    StructuredParams.channelMapping.coordinates = struct();
    
    % Layout information
    StructuredParams.channelMapping.channels.layout = 'Axion16';
    StructuredParams.channelMapping.channels.layoutDetails = struct();
    
    % Channel mapping - standard Axion16 pattern (first 16 channels as example)
    channelLayout = [
        11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28
    ];
    
    for i = 1:16
        StructuredParams.channelMapping.channels.layoutDetails.(['channels_1_' num2str(i)]) = channelLayout(i);
    end
    
    % Coordinates - standard MEA layout (first 16 channels as example)
    StructuredParams.channelMapping.coordinates.coordDetails = struct();
    
    % X coordinates
    for i = 1:16
        xValue = (i-1) * 2.66666666666667;
        if xValue > 8
            xValue = 8;
        end
        StructuredParams.channelMapping.coordinates.coordDetails.(['coords_1_' num2str(i)]) = xValue;
    end
    
    %% 8. Experimental Groups
    StructuredParams.experimentalGroups = struct();
    
    % Determine group types from DIV CSV if available
    groupTypes = {'MUT', 'WM5050', 'WM5050A', 'WM8020A', 'WM9505A', 'WT'};
    if exist(divCsvPath, 'file')
        try
            divData = readtable(divCsvPath);
            if any(strcmpi(divData.Properties.VariableNames, 'Genotype')) || any(strcmpi(divData.Properties.VariableNames, 'group'))
                groupCol = '';
                if any(strcmpi(divData.Properties.VariableNames, 'Genotype'))
                    groupCol = 'Genotype';
                elseif any(strcmpi(divData.Properties.VariableNames, 'group'))
                    groupCol = 'group';
                end
                
                if ~isempty(groupCol)
                    uniqueGroups = unique(divData.(groupCol));
                    groupTypes = uniqueGroups;
                end
            end
        catch
            % Use default group types if there's any issue
        end
    end
    
    StructuredParams.experimentalGroups.groupTypes = groupTypes;
    StructuredParams.experimentalGroups.ALL = 1;
    
    %% 9. Statistics
    StructuredParams.statistics = struct();
    StructuredParams.statistics.doStats = true;
    StructuredParams.statistics.statMethod = 'sem';
    StructuredParams.statistics.statOperations = struct();
    
    %% Update the regular Params structure with essential fields
    % We're keeping the flat Params structure for compatibility
    % with the rest of the code, while also creating the structured version
    
    % Basic parameters
    Params.HomeDir = StructuredParams.fileManagement.paths.homeDir;
    Params.outputDataFolder = StructuredParams.fileManagement.paths.outputDataFolder;
    Params.outputDataFolderName = StructuredParams.fileManagement.paths.outputDataFolderName;
    
    % Convert DIV numbers to comma-separated format to match original
    Params.DivNm = StructuredParams.recordingParameters.divInfo.DivNm;
    
    % Set base parameters
    Params.spikeDetectedData = ''; 
    Params.startAnalysisStep = 1;
    Params.rawData = '';
    Params.guiMode = 0;
    
    % Set spreadSheetFileName to the merged CSV
    if isfield(StructuredParams.fileManagement.files, 'spreadSheetFileName')
        Params.spreadSheetFileName = StructuredParams.fileManagement.files.spreadSheetFileName;
    end
    
    % Network metrics
    if ~isfield(Params, 'NetMetLabelDict')
        Params.NetMetLabelDict = StructuredParams.networkAnalysis.networkMetrics.NetMetLabelDict;
    end
    
    if ~isfield(Params, 'netMetToCal')
        Params.netMetToCal = StructuredParams.networkAnalysis.networkMetrics.netMetToCal;
    end
    
    % Add BCmeantop5 if not already present
    if ~any(strcmp(Params.netMetToCal, 'BCmeantop5'))
        Params.netMetToCal{end+1} = 'BCmeantop5';
    end
    
    % Ensure networkLevelNetMetCustomBounds are set
    if ~isfield(Params, 'networkLevelNetMetCustomBounds')
        Params.networkLevelNetMetCustomBounds = StructuredParams.networkAnalysis.boundaries.networkLevelNetMetCustomBounds;
    end
    
    %% Save the parameter files
    % Save the standard MAT file with the flat Params structure for compatibility
    paramMatFile = fullfile(outputFolder, ['Parameters_' outputFolderName '.mat']);
    save(paramMatFile, 'Params');
    
    % Save the structured parameters in a separate file
    structuredParamMatFile = fullfile(outputFolder, ['StructuredParameters_' outputFolderName '.mat']);
    save(structuredParamMatFile, 'StructuredParams');
    
    if options.verbose
        fprintf('✓ Successfully saved structured parameter files\n');
        fprintf('  Standard MAT file: %s\n', paramMatFile);
        fprintf('  Structured MAT file: %s\n', structuredParamMatFile);
    end
    
    % Create the CSV file using all parameter files to ensure all fields are captured
    % This part will focus on merging channel and coordinate data correctly to match the NAP format
    
    % First, collect all channel and coordinate data from all parameter files
    allChannelData = {};
    allCoordData = {};
    
    for i = 1:length(validFolders)
        % Load the CSV parameter file
        paramCSVFiles = dir(fullfile(validFolders{i}, 'Parameters_*.csv'));
        if ~isempty(paramCSVFiles)
            try
                % Read the CSV file keeping original variable names
                opts = detectImportOptions(fullfile(validFolders{i}, paramCSVFiles(1).name));
                opts.PreserveVariableNames = true;
                T = readtable(fullfile(validFolders{i}, paramCSVFiles(1).name), opts);
                
                % Find all channel and coordinate columns
                colNames = T.Properties.VariableNames;
                channelCols = {};
                coordCols = {};
                
                for j = 1:length(colNames)
                    if strncmp(colNames{j}, 'channels_', 9)
                        channelCols{end+1} = colNames{j};
                    elseif strncmp(colNames{j}, 'coords_', 7)
                        coordCols{end+1} = colNames{j};
                    end
                end
                
                % Store the columns and their data
                allChannelData{end+1} = {T, channelCols};
                allCoordData{end+1} = {T, coordCols};
                
                if options.verbose
                    fprintf('  Found %d channel and %d coordinate columns in %s\n', ...
                        length(channelCols), length(coordCols), validFolders{i});
                end
            catch ME
                warning('Could not read parameter CSV file from %s: %s', validFolders{i}, ME.message);
            end
        end
    end
    
    % Create a new struct for the CSV export without numeric suffixes where possible
    % This will contain all fields from the original parameter files
    tableStruct = struct();
    
    % First, convert the Params struct to a basic structure for the CSV following NAP format conventions
    paramFields = fieldnames(Params);
    for i = 1:length(paramFields)
        fieldName = paramFields{i};
        if ~strcmp(fieldName, 'channels') && ~strcmp(fieldName, 'coords')
            % Handle standard fields
            if isstruct(Params.(fieldName))
                % Expand struct fields with _ separator
                subfields = fieldnames(Params.(fieldName));
                for j = 1:length(subfields)
                    if isscalar(Params.(fieldName).(subfields{j}))
                        tableStruct.([fieldName '_' subfields{j}]) = Params.(fieldName).(subfields{j});
                    end
                end
            elseif iscell(Params.(fieldName))
                % Handle cell arrays - special handling to avoid numeric suffixes when possible
                if length(Params.(fieldName)) == 1
                    % For single items, don't add numeric suffix
                    if ischar(Params.(fieldName){1})
                        tableStruct.(fieldName) = Params.(fieldName){1};
                    elseif isnumeric(Params.(fieldName){1}) && isscalar(Params.(fieldName){1})
                        tableStruct.(fieldName) = Params.(fieldName){1};
                    end
                else
                    % For specific fields with known formats in NAP output
                    if strcmp(fieldName, 'figExt') || strcmp(fieldName, 'lagVal') || strcmp(fieldName, 'thresholds')
                        % Create comma-separated list
                        if all(cellfun(@ischar, Params.(fieldName)))
                            tableStruct.(fieldName) = strjoin(Params.(fieldName), ',');
                        else
                            % Use numeric indices as fallback
                            for j = 1:length(Params.(fieldName))
                                if ischar(Params.(fieldName){j})
                                    tableStruct.([fieldName '_' num2str(j)]) = Params.(fieldName){j};
                                elseif isnumeric(Params.(fieldName){j}) && isscalar(Params.(fieldName){j})
                                    tableStruct.([fieldName '_' num2str(j)]) = Params.(fieldName){j};
                                end
                            end
                        end
                    else
                        % Use numeric indices for other cell arrays
                        for j = 1:length(Params.(fieldName))
                            if ischar(Params.(fieldName){j})
                                tableStruct.([fieldName '_' num2str(j)]) = Params.(fieldName){j};
                            elseif isnumeric(Params.(fieldName){j}) && isscalar(Params.(fieldName){j})
                                tableStruct.([fieldName '_' num2str(j)]) = Params.(fieldName){j};
                            end
                        end
                    end
                end
            elseif isnumeric(Params.(fieldName)) && length(Params.(fieldName)) > 1
                % Handle numeric arrays - special cases for common fields
                if strcmp(fieldName, 'FuncConLagval') || strcmp(fieldName, 'cartographyLagVal') || ...
                   strcmp(fieldName, 'DivNm')
                    % Convert to comma-separated strings to match NAP format
                    tableStruct.(fieldName) = strjoin(cellstr(string(Params.(fieldName))), ',');
                else
                    % Use numeric indices for other arrays
                    for j = 1:length(Params.(fieldName))
                        tableStruct.([fieldName '_' num2str(j)]) = Params.(fieldName)(j);
                    end
                end
            else
                % Handle scalar values and color matrices
                if strcmp(fieldName, 'spikeMethodColors')
                    % Special handling for color matrices
                    if size(Params.(fieldName), 1) <= 21
                        % Convert each row to separate fields matching NAP format
                        for colorIdx = 1:size(Params.(fieldName), 1)
                            tableStruct.(['spikeMethodColors_' num2str(colorIdx) '_1']) = Params.(fieldName)(colorIdx, 1);
                            tableStruct.(['spikeMethodColors_' num2str(colorIdx) '_2']) = Params.(fieldName)(colorIdx, 2);
                            tableStruct.(['spikeMethodColors_' num2str(colorIdx) '_3']) = Params.(fieldName)(colorIdx, 3);
                        end
                    end
                else
                    % Standard scalar value
                    tableStruct.(fieldName) = Params.(fieldName);
                end
            end
        end
    end
    
    %% 7. Create channel and coordinate mappings matching original format
    % Set fixed dimensions to match original format exactly
    maxChannelRow = 48;  % Standard size in original format
    maxChannelCol = 16;
    maxCoordRow = 48;
    maxCoordCol = 32;  % Original uses columns 1-16 for X, 17-32 for Y
    
    % Pattern for extracting row and column from field names like "channels_1_2" or "coords_3_4"
    channelPattern = 'channels_(\d+)_(\d+)';
    coordPattern = 'coords_(\d+)_(\d+)';
    
    % Scan through all parameter files to find the maximum indices
    for i = 1:length(allChannelData)
        if ~isempty(allChannelData{i})
            channelCols = allChannelData{i}{2};
            for j = 1:length(channelCols)
                tokens = regexp(channelCols{j}, channelPattern, 'tokens');
                if ~isempty(tokens) && ~isempty(tokens{1})
                    row = str2double(tokens{1}{1});
                    col = str2double(tokens{1}{2});
                    maxChannelRow = max(maxChannelRow, row);
                    maxChannelCol = max(maxChannelCol, col);
                end
            end
        end
    end
    
    for i = 1:length(allCoordData)
        if ~isempty(allCoordData{i})
            coordCols = allCoordData{i}{2};
            for j = 1:length(coordCols)
                tokens = regexp(coordCols{j}, coordPattern, 'tokens');
                if ~isempty(tokens) && ~isempty(tokens{1})
                    row = str2double(tokens{1}{1});
                    col = str2double(tokens{1}{2});
                    maxCoordRow = max(maxCoordRow, row);
                    maxCoordCol = max(maxCoordCol, col);
                end
            end
        end
    end
    
    % Ensure we have at least 48 rows for channels
    maxChannelRow = max(maxChannelRow, 48);
    maxChannelCol = max(maxChannelCol, 16);
    maxCoordRow = max(maxCoordRow, 48);
    maxCoordCol = max(maxCoordCol, 32);
    
    % Initialize all channel fields with Axion16 layout pattern
    for i = 1:maxChannelRow
        for j = 1:maxChannelCol
            tableStruct.(['channels_' num2str(i) '_' num2str(j)]) = 0;
        end
    end
    
    % Set all channels to use standard Axion16 pattern
    for i = 1:maxChannelRow
        tableStruct.(['channels_' num2str(i) '_1']) = 11;
        tableStruct.(['channels_' num2str(i) '_2']) = 12;
        tableStruct.(['channels_' num2str(i) '_3']) = 13;
        tableStruct.(['channels_' num2str(i) '_4']) = 14;
        tableStruct.(['channels_' num2str(i) '_5']) = 21;
        tableStruct.(['channels_' num2str(i) '_6']) = 22;
        tableStruct.(['channels_' num2str(i) '_7']) = 23;
        tableStruct.(['channels_' num2str(i) '_8']) = 24;
        tableStruct.(['channels_' num2str(i) '_9']) = 31;
        tableStruct.(['channels_' num2str(i) '_10']) = 32;
        tableStruct.(['channels_' num2str(i) '_11']) = 33;
        tableStruct.(['channels_' num2str(i) '_12']) = 34;
        tableStruct.(['channels_' num2str(i) '_13']) = 41;
        tableStruct.(['channels_' num2str(i) '_14']) = 42;
        tableStruct.(['channels_' num2str(i) '_15']) = 43;
        tableStruct.(['channels_' num2str(i) '_16']) = 44;
    end
    
    % Initialize coordinate fields matching original format
    % For X coordinates (j <= 16)
    for i = 1:maxCoordRow
        for j = 1:16
            tableStruct.(['coords_' num2str(i) '_' num2str(j)]) = (j-1) * 2.66666666666667;
        end
    end
    
    % For Y coordinates (j > 16)
    for i = 1:maxCoordRow
        for j = 17:maxCoordCol
            % Use pattern from original format for Y coordinates
            if j-16 <= 4
                tableStruct.(['coords_' num2str(i) '_' num2str(j)]) = 0; 
            elseif j-16 <= 8
                tableStruct.(['coords_' num2str(i) '_' num2str(j)]) = 2.66666666666667;
            elseif j-16 <= 12
                tableStruct.(['coords_' num2str(i) '_' num2str(j)]) = 5.33333333333333;
            else
                tableStruct.(['coords_' num2str(i) '_' num2str(j)]) = 8;
            end
        end
    end
    
    % Now overlay the actual data from all parameter files
    % We'll process them in DIV order, so later DIVs override earlier ones if there's a conflict
    
    % First, prepare a mapping of DIV folders to their row indices in the parameter file
    divToRowIndices = containers.Map('KeyType', 'double', 'ValueType', 'any');
    
    % The default is to map DIV1 to rows 1-24, DIV2 to rows 25-48, etc.
    rowsPerDIV = min(24, floor(maxChannelRow / length(divNumbers)));
    
    % Create the mapping
    for divIdx = 1:length(divNumbers)
        divToRowIndices(divNumbers(divIdx)) = ((divIdx-1) * rowsPerDIV + 1):(divIdx * rowsPerDIV);
    end
    
    % Now overlay each DIV's data to its corresponding rows
    for folderIdx = 1:length(validFolders)
        if ~isempty(allChannelData{folderIdx}) && ~isempty(allCoordData{folderIdx})
            div = divNumbers(folderIdx);
            rowIndices = divToRowIndices(div);
            
            % Get the channel and coordinate data for this DIV
            channelData = allChannelData{folderIdx}{1};
            channelCols = allChannelData{folderIdx}{2};
            
            coordData = allCoordData{folderIdx}{1};
            coordCols = allCoordData{folderIdx}{2};
            
            % Map this DIV's channels to the appropriate rows in our final structure
            for j = 1:length(channelCols)
                % Extract row and column from field name
                tokens = regexp(channelCols{j}, channelPattern, 'tokens');
                if ~isempty(tokens) && ~isempty(tokens{1})
                    sourceRow = str2double(tokens{1}{1});
                    col = str2double(tokens{1}{2});
                    
                    % Map source row to target row using modulo arithmetic
                    % to handle the case where the source has more rows than rowsPerDIV
                    localRowIdx = mod(sourceRow - 1, length(rowIndices)) + 1;
                    targetRow = rowIndices(localRowIdx);
                    
                    % Create the target field name
                    targetField = ['channels_' num2str(targetRow) '_' num2str(col)];
                    
                    % Get the value from the source
                    if ismember(channelCols{j}, channelData.Properties.VariableNames)
                        tableStruct.(targetField) = channelData.(channelCols{j})(1);
                    end
                end
            end
            
            % Map this DIV's coordinates to the appropriate rows
            for j = 1:length(coordCols)
                % Extract row and column from field name
                tokens = regexp(coordCols{j}, coordPattern, 'tokens');
                if ~isempty(tokens) && ~isempty(tokens{1})
                    sourceRow = str2double(tokens{1}{1});
                    col = str2double(tokens{1}{2});
                    
                    % Map source row to target row
                    localRowIdx = mod(sourceRow - 1, length(rowIndices)) + 1;
                    targetRow = rowIndices(localRowIdx);
                    
                    % Create the target field name
                    targetField = ['coords_' num2str(targetRow) '_' num2str(col)];
                    
                    % Get the value from the source
                    if ismember(coordCols{j}, coordData.Properties.VariableNames)
                        tableStruct.(targetField) = coordData.(coordCols{j})(1);
                    end
                end
            end
        end
    end
    
    % Create table from struct
    paramTable = struct2table(tableStruct, 'AsArray', true);
    
    % Sort parameter names to match NAP format (base parameters first, then channels, then coords)
    varNames = paramTable.Properties.VariableNames;
    channelVars = varNames(startsWith(varNames, 'channels_'));
    coordVars = varNames(startsWith(varNames, 'coords_'));
    otherVars = setdiff(varNames, [channelVars, coordVars]);
    
    % Reorder table columns to match NAP format
    paramTable = paramTable(:, [otherVars, channelVars, coordVars]);
    
    % Write to CSV
    paramCSVFile = fullfile(outputFolder, ['Parameters_' outputFolderName '.csv']);
    writetable(paramTable, paramCSVFile);
    
    % Update div3855.csv based on the div_merged.csv format
    divCsvPath = fullfile(outputFolder, 'div_merged.csv');
    namedDivCsvPath = fullfile(outputFolder, ['div' outputFolderName(end-3:end) '.csv']);
    if exist(divCsvPath, 'file')
        copyfile(divCsvPath, namedDivCsvPath);
        if options.verbose
            fprintf('✓ Created named DIV CSV file: %s\n', namedDivCsvPath);
        end
    end
    
    % Create JSON representation of structured parameters
    jsonFileName = fullfile(outputFolder, ['StructuredParameters_' outputFolderName '.json']);
    try
        % Convert struct to JSON with pretty formatting (4-space indentation)
        jsonParams = jsonencode(StructuredParams, 'PrettyPrint', true);
        
        % Write JSON to file
        fid = fopen(jsonFileName, 'w');
        if fid ~= -1
            fprintf(fid, '%s', jsonParams);
            fclose(fid);
            
            if options.verbose
                fprintf('✓ Saved JSON representation of structured parameters: %s\n', jsonFileName);
            end
        else
            warning('Could not write to JSON file: %s', jsonFileName);
        end
    catch ME
        warning('Error creating JSON file: %s', ME.message);
    end
    
    if options.verbose
        fprintf('✓ Successfully created parameter files in organized format\n');
        fprintf('  Standard MAT file: %s\n', paramMatFile);
        fprintf('  Structured MAT file: %s\n', structuredParamMatFile);
        fprintf('  Structured JSON file: %s\n', jsonFileName);
        fprintf('  DIV CSV file: %s\n', namedDivCsvPath);
    end
else
    warning('Could not find a valid parameter file in any of the input folders.');
end

%% Copy channel layout file
% Copy the first available channel_layout.png file
for i = 1:length(validFolders)
    layoutFile = fullfile(validFolders{i}, 'channel_layout.png');
    if exist(layoutFile, 'file')
        copyfile(layoutFile, fullfile(outputFolder, 'channel_layout.png'));
        if options.verbose
            fprintf('✓ Copied channel layout file\n');
        end
        break;
    end
end

%% Create experiment mat files
if options.mergeExperiments
    if options.verbose
        fprintf('\nCreating experiment mat files...\n');
    end
    
    % First check if source folders have ExperimentMatFiles
    hasExpMatFiles = false;
    
    for i = 1:length(validFolders)
        sourceExpFolder = fullfile(validFolders{i}, 'ExperimentMatFiles');
        if exist(sourceExpFolder, 'dir')
            hasExpMatFiles = true;
            matFiles = dir(fullfile(sourceExpFolder, '*.mat'));
            
            if options.verbose
                fprintf('  Found ExperimentMatFiles folder in: %s\n', validFolders{i});
                fprintf('  Contains %d .mat files\n', length(matFiles));
            end
        end
    end
    
    if hasExpMatFiles
        % Get list of all spike files to create experiment mat files for each one
        allSpikeFiles = {};
        for i = 1:length(validFolders)
            spikeFolder = fullfile(validFolders{i}, '1_SpikeDetection', '1A_SpikeDetectedData');
            if exist(spikeFolder, 'dir')
                spikeFiles = dir(fullfile(spikeFolder, '*_spikes.mat'));
                for j = 1:length(spikeFiles)
                    [~, recordingName, ~] = fileparts(spikeFiles(j).name);
                    recordingName = regexprep(recordingName, '_spikes$', ''); % Remove _spikes suffix
                    allSpikeFiles{end+1} = recordingName;
                end
            end
        end
        
        % Remove duplicates
        allSpikeFiles = unique(allSpikeFiles);
        
        % Create placeholder .mat files for each recording
        expFileCounter = 0;
        
        if options.verbose
            fprintf('  Creating %d experiment mat files\n', length(allSpikeFiles));
        end
        
        for i = 1:length(allSpikeFiles)
            recordingName = allSpikeFiles{i};
            outputMatFile = fullfile(experimentMatFolder, [recordingName '_' outputFolderName '.mat']);
            
            % Check if we can find a matching experiment file in any of the source folders
            sourceMatFile = '';
            sourceInfo = [];
            
            for j = 1:length(validFolders)
                sourceExpFolder = fullfile(validFolders{j}, 'ExperimentMatFiles');
                if exist(sourceExpFolder, 'dir')
                    % Look for files matching this recording name
                    expFiles = dir(fullfile(sourceExpFolder, [recordingName '_*.mat']));
                    if ~isempty(expFiles)
                        sourceMatFile = fullfile(sourceExpFolder, expFiles(1).name);
                        try
                            sourceData = load(sourceMatFile);
                            if isfield(sourceData, 'Info')
                                sourceInfo = sourceData.Info;
                                break; % Found it, exit loop
                            end
                        catch
                            % Continue to next folder
                        end
                    end
                end
            end
            
            % If we found a source, copy the Info structure
            if ~isempty(sourceInfo)
                % Update Info fields for the merged output
                Info = sourceInfo;
                Info.createdBy = 'mergeDIVs';
                Info.dateCreated = datestr(now);
                
                % Save the file
                save(outputMatFile, 'Info');
                expFileCounter = expFileCounter + 1;
            else
                % Create a new Info struct with basic information
                
                % Check if we can extract DIV and group info from the filename
                divMatch = regexp(recordingName, '(DIV|div)(\d+)', 'tokens', 'once');
                if ~isempty(divMatch)
                    divValue = str2double(divMatch{2});
                else
                    divValue = 0; % Default if DIV not found
                end
                
                % Try to get group from pattern like NGN2_DIV38_A1
                groupMatch = regexp(recordingName, '_([A-Z])(\d+)', 'tokens', 'once');
                if ~isempty(groupMatch)
                    groupValue = groupMatch{1};
                else
                    groupValue = 'unknown'; % Default group
                end
                
                % Create a proper Info struct with the fields expected by MEA-NAP
                Info = struct();
                Info.FN = {recordingName};
                Info.DIV = {divValue};
                Info.Grp = {groupValue};
                Info.createdBy = 'mergeDIVs';
                Info.dateCreated = datestr(now);
                
                % Save the file
                save(outputMatFile, 'Info');
                expFileCounter = expFileCounter + 1;
            end
        end
        
        if options.verbose
            fprintf('✓ Created %d experiment mat files\n', expFileCounter);
        end
    else
        if options.verbose
            fprintf('No ExperimentMatFiles folders found in any input folder.\n');
        end
    end
end

%% Completion message
if options.verbose
    fprintf('\n=================================================\n');
    fprintf('MEA-NAP DIV Spike Data Merger - COMPLETE\n');
    fprintf('=================================================\n\n');
    fprintf('Successfully merged %d DIV folders into: %s\n\n', length(validFolders), outputFolder);
    fprintf('Merged data can now be used for further MEA-NAP analysis steps\n');
    fprintf('such as neuronal activity, edge thresholding, and network activity\n');
    fprintf('by using this folder as input for the MEApipeline.m function.\n\n');
    
    % Display command to run pipeline on merged data
    paramFilePath = fullfile(outputFolder, ['Parameters_' outputFolderName '.mat']);
    fprintf('To run MEApipeline on this merged data, use the following command:\n');
    fprintf('  MEApipeline(''%s'')\n\n', paramFilePath);
end
end